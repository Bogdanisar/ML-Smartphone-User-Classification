{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!//usr/bin/python3.6\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "splitNum = 405\n",
    "splitMod = 10\n",
    "separator = '=' * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n",
      "900\n",
      "loaded 1000 data\n",
      "==================== \n",
      "\n",
      "loaded 2000 data\n",
      "==================== \n",
      "\n",
      "loaded 3000 data\n",
      "==================== \n",
      "\n",
      "loaded 4000 data\n",
      "==================== \n",
      "\n",
      "loaded 5000 data\n",
      "==================== \n",
      "\n",
      "loaded 6000 data\n",
      "==================== \n",
      "\n",
      "loaded 7000 data\n",
      "==================== \n",
      "\n",
      "loaded 8000 data\n",
      "==================== \n",
      "\n",
      "loaded 9000 data\n",
      "==================== \n",
      "\n",
      "loaded data\n",
      "shape of  15065 is  (149, 3)\n",
      "==============================\n",
      "interpolized data\n",
      "shape of  15065 is  (150, 3)\n",
      "==============================\n",
      "(8100, 450)\n",
      "(900, 450)\n",
      "Fitted the scaler\n",
      "Normalized data\n",
      "Normalized data\n",
      "==============================\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "idToData = {}\n",
    "scaler = None\n",
    "\n",
    "\n",
    "def loadTrainLabels(path):\n",
    "    pairs = np.loadtxt(path, delimiter=',', skiprows=1, dtype=int)\n",
    "    # print(pairs) #############\n",
    "\n",
    "    return pairs[:, 0], pairs[:, 1]\n",
    "\n",
    "def sortData():\n",
    "#     allTrainId, allTrainLabel\n",
    "\n",
    "    indexesOfUser = np.zeros((21, 450), dtype=int)\n",
    "    for u in range(1, 21):\n",
    "        indexesOfUser[u, :] = np.arange(0, allTrainLabel.size)[ (allTrainLabel == u) ]\n",
    "\n",
    "    return indexesOfUser\n",
    "\n",
    "def splitData():\n",
    "    trainArrays = []\n",
    "    validationArrays = []\n",
    "\n",
    "    for u in range(1, 21):\n",
    "        splitted = np.split(indexesOfUser[u, :], [splitNum], axis=0)\n",
    "        \n",
    "        ###############################################\n",
    "#         print(splitted[0].shape)\n",
    "#         print(splitted[1].shape)\n",
    "        \n",
    "        trainArrays.append( splitted[0] )\n",
    "        validationArrays.append( splitted[1] )\n",
    "\n",
    "    trainIndex = np.concatenate(tuple(trainArrays), axis=0)\n",
    "    validationIndex = np.concatenate(tuple(validationArrays), axis=0)\n",
    "    return trainIndex, validationIndex\n",
    "\n",
    "def splitDataMod():\n",
    "    trainArrays = []\n",
    "    validationArrays = []\n",
    "\n",
    "    for u in range(1, 21):\n",
    "#         splitted = np.split(indexesOfUser[u, :], [splitNum], axis=0)\n",
    "        allIndexes = np.arange(0, indexesOfUser[u, :].size)\n",
    "    \n",
    "        trainArrayIndexes = allIndexes[ np.mod(allIndexes, splitMod) != 0 ] \n",
    "        trainArray = indexesOfUser[u, trainArrayIndexes]\n",
    "        \n",
    "        validationArrayIndexes = allIndexes[ np.mod(allIndexes, splitMod) == 0 ] \n",
    "        validationArray = indexesOfUser[u, validationArrayIndexes]\n",
    "        \n",
    "        \n",
    "        ###############################################\n",
    "#         print(splitted[0].shape)\n",
    "#         print(splitted[1].shape)\n",
    "        \n",
    "        trainArrays.append( trainArray )\n",
    "        validationArrays.append( validationArray )\n",
    "\n",
    "    trainIndex = np.concatenate(tuple(trainArrays), axis=0)\n",
    "    validationIndex = np.concatenate(tuple(validationArrays), axis=0)\n",
    "    return trainIndex, validationIndex\n",
    "\n",
    "\n",
    "def loadData(path, ids):\n",
    "    count = 0\n",
    "    for id in ids:\n",
    "        count += 1\n",
    "        idToData[id] = np.loadtxt(path + str(id) + \".csv\", delimiter=',', skiprows=0, dtype=np.float64)\n",
    "\n",
    "        ##################################\n",
    "        if (count % 1000 == 0):\n",
    "            print(\"loaded\", count, \"data\")\n",
    "            # print(idToData[id]) \n",
    "            print(\"=\" * 20, \"\\n\")\n",
    "    \n",
    "    print(\"loaded data\")\n",
    "\n",
    "            \n",
    "\n",
    "def interpolateData(ids):\n",
    "    for id in ids:\n",
    "        array = idToData[id]\n",
    "        newArray = np.zeros((150, 3))\n",
    "\n",
    "        x = np.arange(1, 151, 1)\n",
    "        xp = np.linspace(1, 150, array.shape[0])\n",
    "        for k in range(0, 3):\n",
    "            yp = array[:, k]\n",
    "            newArray[:, k] = np.interp(x, xp, yp)\n",
    "\n",
    "        idToData[id] = newArray\n",
    "\n",
    "    print(\"interpolized data\")\n",
    "            \n",
    "            \n",
    "def getShapedData(ids):\n",
    "    arrays = []\n",
    "    for id in ids:\n",
    "        data = idToData[id]\n",
    "        \n",
    "        ##################################################\n",
    "        data = np.ravel(data, order='C')\n",
    "        \n",
    "        arrays.append(data)\n",
    "    \n",
    "    ret = np.stack(arrays, axis=0)\n",
    "    return ret\n",
    "    \n",
    "    \n",
    "            \n",
    "def fitScaler(shapedData):\n",
    "    global scaler\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(shapedData)\n",
    "\n",
    "    print(\"Fitted the scaler\")\n",
    "\n",
    "\n",
    "def normalize(shapedData):\n",
    "    ret = scaler.transform(shapedData)\n",
    "\n",
    "    print(\"Normalized data\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "def computeProbabilityMatrix():\n",
    "\tprobMatrix = np.zeros((150, numBins ** 3, 21))\n",
    "\n",
    "\tfor userIndex in range(1, 21):\n",
    "\t\tresultBins = np.zeros(idsOfUser[userIndex].size, dtype=int)\n",
    "\t\tfor featureIndex in range(150):\n",
    "\n",
    "\t\t\tfor i in range(idsOfUser[userIndex].size):\n",
    "\t\t\t\tid = idsOfUser[userIndex][i]\n",
    "\t\t\t\tdata = idToData[id]\n",
    "\t\t\t\tresultBins[i] = pointToBin(data[featureIndex, :])\n",
    "\n",
    "\t\t\tfor binIndex in range(numBins ** 3):\n",
    "\t\t\t\tprobMatrix[featureIndex][binIndex][userIndex] = np.sum(resultBins == binIndex) / (resultBins.size)\n",
    "\n",
    "\tprint(\"computed probability matrix\")\n",
    "\treturn probMatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "allTrainId, allTrainLabel = loadTrainLabels(\"../../data/train_labels.csv\")\n",
    "indexesOfUser = sortData()\n",
    "\n",
    "# print(allTrainId); print(separator)\n",
    "# print(allTrainLabel); print(separator)\n",
    "# print(indexesOfUser); print(separator)\n",
    "\n",
    "trainIndex, validationIndex = splitDataMod()\n",
    "\n",
    "trainId = allTrainId[trainIndex]\n",
    "validationId = allTrainId[validationIndex]\n",
    "\n",
    "trainLabel = allTrainLabel[trainIndex]\n",
    "validationLabel = allTrainLabel[validationIndex]\n",
    "##########################################################################\n",
    "print(trainIndex.size)\n",
    "print(validationIndex.size)\n",
    "# print(separator)\n",
    "# print(trainIndex)\n",
    "# print(validationIndex)\n",
    "\n",
    "\n",
    "printId = 15065\n",
    "\n",
    "loadData(\"../../data/train/\", allTrainId)\n",
    "# print(idToData[10003]) ##################\n",
    "print(\"shape of \", printId, \"is \", idToData[printId].shape) ##################\n",
    "print(separator)\n",
    "\n",
    "interpolateData(allTrainId)\n",
    "# print(idToData[10003]) ##################\n",
    "print(\"shape of \", printId, \"is \", idToData[printId].shape) ##################\n",
    "# print(\"data of \", printId, \"is \", idToData[printId])\n",
    "print(separator)\n",
    "\n",
    "shapedTrainData = getShapedData(trainId)\n",
    "shapedValidationData = getShapedData(validationId)\n",
    "print(shapedTrainData.shape)\n",
    "print(shapedValidationData.shape)\n",
    "\n",
    "fitScaler(shapedTrainData)\n",
    "shapedTrainData = normalize(shapedTrainData)\n",
    "shapedValidationData = normalize(shapedValidationData)\n",
    "\n",
    "\n",
    "print(separator)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = np.arange(0, trainId.size)[trainId == printId][0]\n",
    "print(\"aux =\", aux, \"trainId[aux] =\", trainId[aux])\n",
    "print(\"data of \", printId, \"is \", shapedTrainData[aux]) ##################\n",
    "print(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting do validation\n",
      "accuracy of validation =  0.9377777777777778  where splitMod = 10\n",
      "C = 10, kernel = rbf, gamma = scale\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# do validation\n",
    "\n",
    "print(\"starting do validation\")\n",
    "\n",
    "def doValidationRBF(C, g):\n",
    "    svm_model = svm.SVC(C=C, kernel='rbf', gamma=g)\n",
    "    svm_model.fit(shapedTrainData, trainLabel)\n",
    "    predictedLabels = svm_model.predict(shapedValidationData)\n",
    "\n",
    "    # print(predictedLabels); print(separator)\n",
    "\n",
    "    accuracy = (predictedLabels == validationLabel).sum() / validationLabel.size\n",
    "    print(\"accuracy of validation = \", accuracy, \" where splitMod =\", splitMod)\n",
    "    print(\"C = %s, kernel = %s, gamma = %s\" % (C, \"rbf\", g))\n",
    "\n",
    "# Cs = np.array([1e-10, 1e-9, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0, 1, 10])\n",
    "# Cs = np.array([1e-8, 1e-7, 1e-6, 1e-3, 1e-1, 1, 10][::-1])\n",
    "# Cs = np.array([1e-8, 1e-7, 1e-6, 1e-3, 1e-1, 1, 10])\n",
    "# Gammas = ['scale', 'auto', 1e-5, 1e-1, 10]\n",
    "\n",
    "# Cs = np.logspace(-2, 10, 4)\n",
    "# Cs = [1.0, 10]\n",
    "# Gammas = np.logspace(-6, 3, 10)\n",
    "# Gammas = ['scale', 'auto'] + list(Gammas)\n",
    "\n",
    "# print(\"Cs =\", Cs)\n",
    "# print(\"Gammas =\", Gammas)\n",
    "# for c in Cs:\n",
    "#     for g in Gammas:\n",
    "#         doValidationRBF(c, g)\n",
    "\n",
    "doValidationRBF(10, 'scale')\n",
    "    \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10001 10002 10004 ... 23992 23998 24000]\n",
      "loaded 1000 data\n",
      "==================== \n",
      "\n",
      "loaded 2000 data\n",
      "==================== \n",
      "\n",
      "loaded 3000 data\n",
      "==================== \n",
      "\n",
      "loaded 4000 data\n",
      "==================== \n",
      "\n",
      "loaded 5000 data\n",
      "==================== \n",
      "\n",
      "loaded data\n",
      "interpolized data\n",
      "(8100, 450)\n",
      "Normalized data\n",
      "predicted the labels as:\n",
      "[ 3 10  5 ... 10  5  1]\n",
      "done with writing\n"
     ]
    }
   ],
   "source": [
    "# for predicting on test data:\n",
    "mask = np.ones(24000 + 1, dtype=bool)\n",
    "mask[allTrainId] = False\n",
    "mask = mask[10001 : 24000 + 1]\n",
    "testId = np.arange(10001, 24000 + 1)[mask]\n",
    "\n",
    "print(testId)\n",
    "\n",
    "\n",
    "\n",
    "loadData(\"../../data/test/\", testId)\n",
    "\n",
    "interpolateData(testId)\n",
    "shapedTestData = getShapedData(testId)\n",
    "\n",
    "#######################################\n",
    "print(shapedTrainData.shape)\n",
    "\n",
    "shapedTestData = normalize(shapedTestData)\n",
    "\n",
    "\n",
    "\n",
    "# svm_model = svm.SVC(svm_C, svm_kernel)\n",
    "svm_model = svm.SVC(C=10, kernel='rbf', gamma='scale')\n",
    "svm_model.fit(shapedTrainData, trainLabel)\n",
    "predictedLabels = svm_model.predict(shapedTestData)\n",
    "\n",
    "print(\"predicted the labels as:\")\n",
    "print(predictedLabels)\n",
    "\n",
    "np.savetxt(\"result.csv\", np.stack((testId, predictedLabels)).T, fmt=\"%s\", delimiter=',', header=\"id,class\", comments='')\n",
    "print(\"done with writing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True]\n",
      "[1 2]\n",
      "[ 1.    3.25  5.5   7.75 10.  ]\n",
      "[False  True False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# for testing stuff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(1,5)\n",
    "print(a % 2 == 0)\n",
    "\n",
    "b = np.arange(1,5)\n",
    "print(b[ np.array([True, True, False, False]) ])\n",
    "\n",
    "print(np.linspace(1, 10, 5))\n",
    "\n",
    "print(~np.array([True, False, True, False, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}